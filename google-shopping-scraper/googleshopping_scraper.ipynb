{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88e1e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.4.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75b2ec",
   "metadata": {},
   "source": [
    "## Google Shopping Scraper (Paginated + Cleaned)\n",
    "\n",
    "This script scrapes Google Shopping results using **SerpApi** with pagination support.  \n",
    "\n",
    "**Features:**\n",
    "- Fetches up to 5 pages of products (configurable with `MAX_PAGES`).\n",
    "- Extracts **title, price (INR), source, and direct merchant link**.\n",
    "- Deduplicates results (avoids repeating the same product).\n",
    "- Adds small delays between pages to respect API usage.\n",
    "- Saves results into a **CSV file** (`google_shopping_results.csv`) with proper encoding so `â‚¹` is displayed correctly in Excel.\n",
    "\n",
    "**CSV Columns:**\n",
    "- Title  \n",
    "- Price (INR)  \n",
    "- Source (merchant name)  \n",
    "- Link (direct product link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Fetching page 1 (start=0) â€¦\n",
      "ðŸ›’ Found 40 raw items; added 40 unique items.\n",
      "ðŸ”Ž Fetching page 2 (start=40) â€¦\n",
      "ðŸ›’ Found 22 raw items; added 22 unique items.\n",
      "ðŸ”Ž Fetching page 3 (start=62) â€¦\n",
      "âœ… No more products found. Stopping.\n",
      "âœ… Saved 62 items to 'google_shopping_results.csv'\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import csv\n",
    "import time\n",
    "\n",
    "API_KEY = Your_api_key      \n",
    "SEARCH_TERM = \"Nothing 45W charger\"        \n",
    "CSV_FILE = \"google_shopping_results.csv\"   \n",
    "MAX_PAGES = 5                              \n",
    "SLEEP_BETWEEN_PAGES = 1.2                   \n",
    "\n",
    "# Country/language/currency for India\n",
    "GL = \"in\"\n",
    "HL = \"en\"\n",
    "CURRENCY = \"INR\"\n",
    "\n",
    "\n",
    "def normalize_price(p: str) -> str:\n",
    "    \"\"\"Return price string as-is but ensure it's a string (handle None).\"\"\"\n",
    "    return (p or \"\").strip()\n",
    "\n",
    "def get_direct_link(product: dict) -> str:\n",
    "    \"\"\"\n",
    "    Prefer the merchant's direct product link over Google redirect links.\n",
    "    SerpApi often provides:\n",
    "      - product_link: merchant page (preferred)\n",
    "      - link: sometimes Google redirect (fallback)\n",
    "    \"\"\"\n",
    "    link = product.get(\"product_link\") or product.get(\"link\") or \"\"\n",
    "    return link.strip()\n",
    "\n",
    "def extract_items(products):\n",
    "    \"\"\"Yield cleaned items (title, price, source, link) from SerpApi items.\"\"\"\n",
    "    for p in products:\n",
    "        title = (p.get(\"title\") or \"\").strip()\n",
    "        price = normalize_price(p.get(\"price\"))\n",
    "        source = (p.get(\"source\") or \"\").strip()\n",
    "        link = get_direct_link(p)\n",
    "\n",
    "        # Skip obviously bad/empty links\n",
    "        if not link:\n",
    "            continue\n",
    "\n",
    "        yield {\n",
    "            \"title\": title,\n",
    "            \"price\": price,\n",
    "            \"source\": source,\n",
    "            \"link\": link,\n",
    "        }\n",
    "\n",
    "def scrape_google_shopping(query: str):\n",
    "    \"\"\"\n",
    "    Paginate through Google Shopping results via SerpApi.\n",
    "    Returns a list of unique items.\n",
    "    \"\"\"\n",
    "    results_all = []\n",
    "    seen_links = set()\n",
    "\n",
    "    start = 0\n",
    "    page = 1\n",
    "\n",
    "    while page <= MAX_PAGES:\n",
    "        params = {\n",
    "            \"engine\": \"google_shopping\",\n",
    "            \"api_key\": API_KEY,\n",
    "            \"q\": query,\n",
    "            \"gl\": GL,                 # country\n",
    "            \"hl\": HL,                 # language\n",
    "            \"currency\": CURRENCY,     # show prices in INR\n",
    "            \"start\": start,           # pagination offset\n",
    "        }\n",
    "\n",
    "        print(f\"ðŸ”Ž Fetching page {page} (start={start}) â€¦\")\n",
    "        search = GoogleSearch(params)\n",
    "        data = search.get_dict()\n",
    "\n",
    "        # SerpApi returns shopping results in this key\n",
    "        products = data.get(\"shopping_results\", []) or []\n",
    "\n",
    "        # Sometimes items appear under 'inline_shopping_results' (rare)\n",
    "        if not products and \"inline_shopping_results\" in data:\n",
    "            products = data[\"inline_shopping_results\"]\n",
    "\n",
    "        if not products:\n",
    "            print(\"âœ… No more products found. Stopping.\")\n",
    "            break\n",
    "\n",
    "        count_before = len(results_all)\n",
    "        for item in extract_items(products):\n",
    "            if item[\"link\"] not in seen_links:\n",
    "                seen_links.add(item[\"link\"])\n",
    "                results_all.append(item)\n",
    "\n",
    "        added = len(results_all) - count_before\n",
    "        print(f\"ðŸ›’ Found {len(products)} raw items; added {added} unique items.\")\n",
    "\n",
    "        # Next page\n",
    "        page += 1\n",
    "        start += len(products) \n",
    "        time.sleep(SLEEP_BETWEEN_PAGES)\n",
    "\n",
    "    return results_all\n",
    "\n",
    "def save_csv(items, filename):\n",
    "    # Use utf-8-sig to display â‚¹ correctly in Excel\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Title\", \"Price (INR)\", \"Source\", \"Link\"])\n",
    "        for it in items:\n",
    "            writer.writerow([it[\"title\"], it[\"price\"], it[\"source\"], it[\"link\"]])\n",
    "    print(f\"âœ… Saved {len(items)} items to '{filename}'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    items = scrape_google_shopping(SEARCH_TERM)\n",
    "    if not items:\n",
    "        print(\"âŒ No products extracted. Try a broader query or check your API key/quota.\")\n",
    "    else:\n",
    "        save_csv(items, CSV_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b0653",
   "metadata": {},
   "source": [
    "## Google Shopping Scraper (Single Page, Quick Version)\n",
    "\n",
    "This is a **simpler scraper** that fetches only the **first page** of Google Shopping results for a given query.  \n",
    "\n",
    "**Features:**\n",
    "- Extracts **title, price, source, and link** from the first page only.\n",
    "- Uses fewer API calls (good for saving quota).\n",
    "- Saves data into `shopping_results.csv`.\n",
    "\n",
    "**CSV Columns:**\n",
    "- Title  \n",
    "- Price  \n",
    "- Link  \n",
    "- Source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae14436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 40 items to shopping_results.csv\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import csv\n",
    "\n",
    "API_KEY = Your_api_key\n",
    "SEARCH_TERM = \"Nothing 45W charger\"\n",
    "\n",
    "params = {\n",
    "    \"engine\": \"google_shopping\",\n",
    "    \"api_key\": API_KEY,\n",
    "    \"q\": SEARCH_TERM,\n",
    "    \"gl\": \"in\",     # country India\n",
    "    \"hl\": \"en\",     # language English\n",
    "    \"currency\": \"INR\"\n",
    "}\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "products = results.get(\"shopping_results\", [])\n",
    "\n",
    "with open(\"shopping_results.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Title\", \"Price\", \"Link\", \"Source\"])\n",
    "    for p in products:\n",
    "        title = p.get(\"title\", \"\")\n",
    "        price = p.get(\"price\", \"\")\n",
    "        link = p.get(\"product_link\") or p.get(\"link\", \"\")  # direct link preferred\n",
    "        source = p.get(\"source\", \"\")\n",
    "        writer.writerow([title, price, link, source])\n",
    "\n",
    "print(f\"âœ… Saved {len(products)} items to shopping_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
